{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sscc37/C.Language/blob/0529-yolov8-learning/yolov8_train_segment.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "uqXkKmGG_M1o"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1. 초기 환경 설정"
      ],
      "metadata": {
        "id": "RDBxDqGn_Oyo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# YOLOv8 설치\n",
        "!pip install ultralytics"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FE89CJIq_PZO",
        "outputId": "e1c6d8dd-6208-48f7-af8b-0c6949de53a5"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting ultralytics\n",
            "  Downloading ultralytics-8.3.146-py3-none-any.whl.metadata (37 kB)\n",
            "Requirement already satisfied: numpy>=1.23.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (2.0.2)\n",
            "Requirement already satisfied: matplotlib>=3.3.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (3.10.0)\n",
            "Requirement already satisfied: opencv-python>=4.6.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (4.11.0.86)\n",
            "Requirement already satisfied: pillow>=7.1.2 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (11.2.1)\n",
            "Requirement already satisfied: pyyaml>=5.3.1 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (6.0.2)\n",
            "Requirement already satisfied: requests>=2.23.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (2.32.3)\n",
            "Requirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (1.15.3)\n",
            "Requirement already satisfied: torch>=1.8.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (2.6.0+cu124)\n",
            "Requirement already satisfied: torchvision>=0.9.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (0.21.0+cu124)\n",
            "Requirement already satisfied: tqdm>=4.64.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (4.67.1)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from ultralytics) (5.9.5)\n",
            "Requirement already satisfied: py-cpuinfo in /usr/local/lib/python3.11/dist-packages (from ultralytics) (9.0.0)\n",
            "Requirement already satisfied: pandas>=1.1.4 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (2.2.2)\n",
            "Collecting ultralytics-thop>=2.0.0 (from ultralytics)\n",
            "  Downloading ultralytics_thop-2.0.14-py3-none-any.whl.metadata (9.4 kB)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (1.3.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (4.58.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (1.4.8)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (24.2)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (3.2.3)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.1.4->ultralytics) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.1.4->ultralytics) (2025.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.23.0->ultralytics) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.23.0->ultralytics) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.23.0->ultralytics) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.23.0->ultralytics) (2025.4.26)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (4.13.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (2025.3.2)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch>=1.8.0->ultralytics)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch>=1.8.0->ultralytics)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch>=1.8.0->ultralytics)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch>=1.8.0->ultralytics)\n",
            "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch>=1.8.0->ultralytics)\n",
            "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch>=1.8.0->ultralytics)\n",
            "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.5.147 (from torch>=1.8.0->ultralytics)\n",
            "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch>=1.8.0->ultralytics)\n",
            "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch>=1.8.0->ultralytics)\n",
            "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (12.4.127)\n",
            "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch>=1.8.0->ultralytics)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=1.8.0->ultralytics) (1.3.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.7->matplotlib>=3.3.0->ultralytics) (1.17.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=1.8.0->ultralytics) (3.0.2)\n",
            "Downloading ultralytics-8.3.146-py3-none-any.whl (1.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m19.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m87.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m63.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m50.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m14.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m7.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m106.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ultralytics_thop-2.0.14-py3-none-any.whl (26 kB)\n",
            "Installing collected packages: nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, ultralytics-thop, ultralytics\n",
            "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
            "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n",
            "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
            "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
            "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
            "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
            "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
            "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
            "Successfully installed nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127 ultralytics-8.3.146 ultralytics-thop-2.0.14\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 필요한 라이브러리 임포트\n",
        "import os\n",
        "from ultralytics import YOLO\n",
        "import shutil\n",
        "from google.colab import drive\n",
        "from google.colab import files"
      ],
      "metadata": {
        "id": "d-qGX-P__Rl_",
        "outputId": "00ff56e4-66a2-449a-dc29-83bc3a2831cd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Creating new Ultralytics Settings v0.0.6 file ✅ \n",
            "View Ultralytics Settings with 'yolo settings' or at '/root/.config/Ultralytics/settings.json'\n",
            "Update Settings with 'yolo settings key=value', i.e. 'yolo settings runs_dir=path/to/dir'. For help see https://docs.ultralytics.com/quickstart/#ultralytics-settings.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 파일 선택기를 통한 업로드/ 학습된 zip 파일을 다운로드 한다.\n",
        "uploaded = files.upload()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 78
        },
        "id": "uQTVgvdM_o_g",
        "outputId": "fe5f6dbf-e2c9-4ccd-e957-7f2fb26764a6"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-69985a3e-151f-424a-a3e7-cf86eb692c6d\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-69985a3e-151f-424a-a3e7-cf86eb692c6d\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving test.v1i.yolov8.zip to test.v1i.yolov8.zip\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 코랩 셀에서 ! 를 앞에 붙여서 실행\n",
        "!mkdir -p /content/dataset\n",
        "!unzip /content/test.v1i.yolov8.zip -d /content/dataset"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "64QbLdrJAbTV",
        "outputId": "8f36426b-8b93-4c86-a14f-582ad8b27a44"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  /content/test.v1i.yolov8.zip\n",
            "  inflating: /content/dataset/README.dataset.txt  \n",
            "  inflating: /content/dataset/README.roboflow.txt  \n",
            "  inflating: /content/dataset/data.yaml  \n",
            "   creating: /content/dataset/train/\n",
            "   creating: /content/dataset/train/images/\n",
            " extracting: /content/dataset/train/images/121-_jpg.rf.d36e70fd2de33b8b6cc77160a7088b6f.jpg  \n",
            " extracting: /content/dataset/train/images/122-_jpg.rf.9c46815cf488d2659f9a7258abf27029.jpg  \n",
            " extracting: /content/dataset/train/images/123-_jpg.rf.a228c18f448d90fe3ef627dd4b92b7ed.jpg  \n",
            " extracting: /content/dataset/train/images/124-_jpg.rf.9ab2f9ebb0279f89ce2b5dacb8b1083f.jpg  \n",
            " extracting: /content/dataset/train/images/125-_jpg.rf.e4a04a05e6a6374afe927c8ff9045546.jpg  \n",
            " extracting: /content/dataset/train/images/126-_jpg.rf.52a46fd704e8f5eee804bc7d95104d8e.jpg  \n",
            " extracting: /content/dataset/train/images/127-_jpg.rf.46c2cbd52bea81fb4bffd502d92cbb04.jpg  \n",
            " extracting: /content/dataset/train/images/128-_jpg.rf.026b7a4bce903ffb6b692fe4265b9393.jpg  \n",
            " extracting: /content/dataset/train/images/129-_jpg.rf.da642d39016bb4ea3453e6126a3ba956.jpg  \n",
            " extracting: /content/dataset/train/images/130-_jpg.rf.0075a5215851d7d1218b78d4c9169c81.jpg  \n",
            " extracting: /content/dataset/train/images/131-_jpg.rf.155c503822acb1429a74645b2dd31584.jpg  \n",
            " extracting: /content/dataset/train/images/132-_jpg.rf.e122b352a1f34bee5bccf7f999136c24.jpg  \n",
            " extracting: /content/dataset/train/images/133-_jpg.rf.a8edc577127d808151a5509733a01a3b.jpg  \n",
            " extracting: /content/dataset/train/images/134-_jpg.rf.538c2b19ef92599439257bf73c2a4343.jpg  \n",
            " extracting: /content/dataset/train/images/135-_jpg.rf.895917461ff3b64960b12caa4a11cdd7.jpg  \n",
            "   creating: /content/dataset/train/labels/\n",
            "  inflating: /content/dataset/train/labels/121-_jpg.rf.d36e70fd2de33b8b6cc77160a7088b6f.txt  \n",
            "  inflating: /content/dataset/train/labels/122-_jpg.rf.9c46815cf488d2659f9a7258abf27029.txt  \n",
            "  inflating: /content/dataset/train/labels/123-_jpg.rf.a228c18f448d90fe3ef627dd4b92b7ed.txt  \n",
            "  inflating: /content/dataset/train/labels/124-_jpg.rf.9ab2f9ebb0279f89ce2b5dacb8b1083f.txt  \n",
            "  inflating: /content/dataset/train/labels/125-_jpg.rf.e4a04a05e6a6374afe927c8ff9045546.txt  \n",
            "  inflating: /content/dataset/train/labels/126-_jpg.rf.52a46fd704e8f5eee804bc7d95104d8e.txt  \n",
            "  inflating: /content/dataset/train/labels/127-_jpg.rf.46c2cbd52bea81fb4bffd502d92cbb04.txt  \n",
            "  inflating: /content/dataset/train/labels/128-_jpg.rf.026b7a4bce903ffb6b692fe4265b9393.txt  \n",
            "  inflating: /content/dataset/train/labels/129-_jpg.rf.da642d39016bb4ea3453e6126a3ba956.txt  \n",
            "  inflating: /content/dataset/train/labels/130-_jpg.rf.0075a5215851d7d1218b78d4c9169c81.txt  \n",
            "  inflating: /content/dataset/train/labels/131-_jpg.rf.155c503822acb1429a74645b2dd31584.txt  \n",
            "  inflating: /content/dataset/train/labels/132-_jpg.rf.e122b352a1f34bee5bccf7f999136c24.txt  \n",
            "  inflating: /content/dataset/train/labels/133-_jpg.rf.a8edc577127d808151a5509733a01a3b.txt  \n",
            "  inflating: /content/dataset/train/labels/134-_jpg.rf.538c2b19ef92599439257bf73c2a4343.txt  \n",
            "  inflating: /content/dataset/train/labels/135-_jpg.rf.895917461ff3b64960b12caa4a11cdd7.txt  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "다음 폴더 구조를 수정합니다.\n",
        "\n",
        "\n",
        "content/\n",
        "\n",
        "├── dataset\n",
        "│   ├──train\n",
        "│   │   ├──images\n",
        "│   │   ├──labels\n",
        "│   ├──valid\n",
        "│   │   ├──images\n",
        "│   ├──test\n",
        "│   │   ├──images\n",
        "└── data.yaml\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "wMGew12kCjr_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#test/images 폴더 생성\n",
        "!mkdir -p /content/dataset/test/images\n",
        "!cp /content/dataset/train/images/* /content/dataset/test/images/"
      ],
      "metadata": {
        "id": "J5zMVpsfDMAP",
        "outputId": "ff89296e-57a0-4029-e8bb-25fde36a25db",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cp: cannot stat '/content/dataset/train/images/*': No such file or directory\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#valid/images 폴더 생성\n",
        "!mkdir -p /content/dataset/valid/images\n",
        "!cp /content/dataset/train/images/* /content/dataset/valid/images/"
      ],
      "metadata": {
        "id": "wwpPo3avCnUa",
        "outputId": "53285082-8778-4fbe-d6d7-e2848f9be113",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cp: cannot stat '/content/dataset/train/images/*': No such file or directory\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#valid/labels 폴더 생성\n",
        "!mkdir -p /content/dataset/valid/labels\n",
        "!cp /content/dataset/train/labels/* /content/dataset/valid/labels/"
      ],
      "metadata": {
        "id": "cNM3W9F0LFOv",
        "outputId": "ff3b6ef8-fc78-4bdd-ac02-40932a7bb58f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cp: cannot stat '/content/dataset/train/labels/*': No such file or directory\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#data.yaml 파일 수정\n",
        "\n",
        "train: /content/dataset/train/images\n",
        "val: /content/dataset/valid/images\n",
        "test: /content/dataset/test/images"
      ],
      "metadata": {
        "id": "Jd7xutFOI-38"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 학습 시작\n",
        "from ultralytics import YOLO\n",
        "\n",
        "# Segmentation 모델로 학습\n",
        "model = YOLO('yolov8l-seg.pt')  # segmentation 모델 사용\n",
        "\n",
        "results = model.train(\n",
        "    data='/content/dataset/data.yaml',\n",
        "    epochs=50,\n",
        "    imgsz=640,\n",
        "    batch=16,\n",
        "    name='yolov8_seg_custom',\n",
        "    project='/content/runs/train',\n",
        "    patience=0,\n",
        "    save=True,\n",
        "    device=0\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "cV-y5kGuJa37",
        "outputId": "7569b8b2-499a-4272-e592-31601900dfba"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ultralytics 8.3.146 🚀 Python-3.11.12 torch-2.6.0+cu124 CUDA:0 (Tesla T4, 15095MiB)\n",
            "\u001b[34m\u001b[1mengine/trainer: \u001b[0magnostic_nms=False, amp=True, augment=False, auto_augment=randaugment, batch=16, bgr=0.0, box=7.5, cache=False, cfg=None, classes=None, close_mosaic=10, cls=0.5, conf=None, copy_paste=0.0, copy_paste_mode=flip, cos_lr=False, cutmix=0.0, data=/content/dataset/data.yaml, degrees=0.0, deterministic=True, device=0, dfl=1.5, dnn=False, dropout=0.0, dynamic=False, embed=None, epochs=50, erasing=0.4, exist_ok=False, fliplr=0.5, flipud=0.0, format=torchscript, fraction=1.0, freeze=None, half=False, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, imgsz=640, int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=0.01, lrf=0.01, mask_ratio=4, max_det=300, mixup=0.0, mode=train, model=yolov8l-seg.pt, momentum=0.937, mosaic=1.0, multi_scale=False, name=yolov8_seg_custom3, nbs=64, nms=False, opset=None, optimize=False, optimizer=auto, overlap_mask=True, patience=0, perspective=0.0, plots=True, pose=12.0, pretrained=True, profile=False, project=/content/runs/train, rect=False, resume=False, retina_masks=False, save=True, save_conf=False, save_crop=False, save_dir=/content/runs/train/yolov8_seg_custom3, save_frames=False, save_json=False, save_period=-1, save_txt=False, scale=0.5, seed=0, shear=0.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=segment, time=None, tracker=botsort.yaml, translate=0.1, val=True, verbose=True, vid_stride=1, visualize=False, warmup_bias_lr=0.1, warmup_epochs=3.0, warmup_momentum=0.8, weight_decay=0.0005, workers=8, workspace=None\n",
            "Overriding model.yaml nc=80 with nc=5\n",
            "\n",
            "                   from  n    params  module                                       arguments                     \n",
            "  0                  -1  1      1856  ultralytics.nn.modules.conv.Conv             [3, 64, 3, 2]                 \n",
            "  1                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
            "  2                  -1  3    279808  ultralytics.nn.modules.block.C2f             [128, 128, 3, True]           \n",
            "  3                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
            "  4                  -1  6   2101248  ultralytics.nn.modules.block.C2f             [256, 256, 6, True]           \n",
            "  5                  -1  1   1180672  ultralytics.nn.modules.conv.Conv             [256, 512, 3, 2]              \n",
            "  6                  -1  6   8396800  ultralytics.nn.modules.block.C2f             [512, 512, 6, True]           \n",
            "  7                  -1  1   2360320  ultralytics.nn.modules.conv.Conv             [512, 512, 3, 2]              \n",
            "  8                  -1  3   4461568  ultralytics.nn.modules.block.C2f             [512, 512, 3, True]           \n",
            "  9                  -1  1    656896  ultralytics.nn.modules.block.SPPF            [512, 512, 5]                 \n",
            " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 12                  -1  3   4723712  ultralytics.nn.modules.block.C2f             [1024, 512, 3]                \n",
            " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 15                  -1  3   1247744  ultralytics.nn.modules.block.C2f             [768, 256, 3]                 \n",
            " 16                  -1  1    590336  ultralytics.nn.modules.conv.Conv             [256, 256, 3, 2]              \n",
            " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 18                  -1  3   4592640  ultralytics.nn.modules.block.C2f             [768, 512, 3]                 \n",
            " 19                  -1  1   2360320  ultralytics.nn.modules.conv.Conv             [512, 512, 3, 2]              \n",
            " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 21                  -1  3   4723712  ultralytics.nn.modules.block.C2f             [1024, 512, 3]                \n",
            " 22        [15, 18, 21]  1   7892863  ultralytics.nn.modules.head.Segment          [5, 32, 256, [256, 512, 512]] \n",
            "YOLOv8l-seg summary: 231 layers, 45,939,903 parameters, 45,939,887 gradients, 220.8 GFLOPs\n",
            "\n",
            "Transferred 651/657 items from pretrained weights\n",
            "Freezing layer 'model.22.dfl.conv.weight'\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mFast image access ✅ (ping: 0.1±0.2 ms, read: 666.8±299.0 MB/s, size: 21.9 KB)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /content/dataset/train/labels.cache... 15 images, 0 backgrounds, 0 corrupt: 100%|██████████| 15/15 [00:00<?, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, method='weighted_average', num_output_channels=3), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[34m\u001b[1mval: \u001b[0mFast image access ✅ (ping: 0.0±0.0 ms, read: 411.8±188.5 MB/s, size: 21.9 KB)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mval: \u001b[0mScanning /content/dataset/train/labels.cache... 15 images, 0 backgrounds, 0 corrupt: 100%|██████████| 15/15 [00:00<?, ?it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Plotting labels to /content/runs/train/yolov8_seg_custom3/labels.jpg... \n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.001111, momentum=0.9) with parameter groups 106 weight(decay=0.0), 117 weight(decay=0.0005), 116 bias(decay=0.0)\n",
            "Image sizes 640 train, 640 val\n",
            "Using 2 dataloader workers\n",
            "Logging results to \u001b[1m/content/runs/train/yolov8_seg_custom3\u001b[0m\n",
            "Starting training for 50 epochs...\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "       1/50      10.3G      1.781      4.337      3.573      1.716        266        640: 100%|██████████| 1/1 [00:02<00:00,  3.00s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.29it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all         15        150    0.00513      0.236     0.0185     0.0133        0.8    0.00508     0.0147     0.0122\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "       2/50      10.3G      1.753      4.865      3.578      1.728        254        640: 100%|██████████| 1/1 [00:01<00:00,  1.09s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.47it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all         15        150    0.00529      0.238     0.0195     0.0136        0.8    0.00479     0.0154     0.0127\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "       3/50      10.2G      1.875      4.946      3.483      1.833        226        640: 100%|██████████| 1/1 [00:00<00:00,  1.04it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.76it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all         15        150    0.00528      0.238       0.02     0.0139        0.8    0.00453     0.0158     0.0132\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "       4/50      10.3G      1.902      5.091      3.678       1.77        274        640: 100%|██████████| 1/1 [00:00<00:00,  1.03it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  2.33it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all         15        150    0.00529      0.238     0.0214     0.0147        0.8    0.00452     0.0169      0.014\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "       5/50      10.3G      1.664      4.841      3.653      1.703        300        640: 100%|██████████| 1/1 [00:00<00:00,  1.03it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  2.36it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all         15        150     0.0059      0.251      0.022     0.0148        0.8     0.0045      0.017     0.0141\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "       6/50      10.3G      1.718        5.4      3.525      1.764        259        640: 100%|██████████| 1/1 [00:00<00:00,  1.04it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  2.31it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all         15        150    0.00589      0.251      0.022     0.0147        0.8    0.00446     0.0168     0.0139\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "       7/50      10.3G      1.777      5.275      3.605      1.702        270        640: 100%|██████████| 1/1 [00:01<00:00,  1.06s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.97it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all         15        150    0.00533      0.238     0.0219     0.0148        0.8    0.00505     0.0172     0.0142\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "       8/50      10.3G      1.776      4.503       3.73      1.617        263        640: 100%|██████████| 1/1 [00:00<00:00,  1.04it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  2.36it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all         15        150    0.00592      0.251     0.0225     0.0148        0.8    0.00502     0.0173     0.0143\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "       9/50      10.4G       1.75      4.843      3.653      1.763        267        640: 100%|██████████| 1/1 [00:01<00:00,  1.08s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  2.29it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all         15        150      0.403       0.32      0.327      0.217      0.375      0.253      0.258      0.153\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      10/50      10.7G      1.086      3.013      2.402      1.311        262        640: 100%|██████████| 1/1 [00:00<00:00,  1.02it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  2.19it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all         15        150       0.59      0.449      0.438      0.307      0.539      0.405      0.373      0.186\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      11/50      10.8G     0.9069      2.233       2.26      1.165        273        640: 100%|██████████| 1/1 [00:00<00:00,  1.01it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  2.20it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all         15        150        0.8      0.746      0.859      0.508      0.696      0.641      0.665      0.379\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      12/50      10.6G     0.9943      2.041      1.612      1.212        196        640: 100%|██████████| 1/1 [00:00<00:00,  1.02it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  2.18it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all         15        150      0.625      0.769      0.713      0.467       0.46      0.608        0.6      0.335\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      13/50      10.6G     0.7624      1.762      1.592      1.155        201        640: 100%|██████████| 1/1 [00:01<00:00,  1.06s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  2.04it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all         15        150      0.728      0.831      0.874      0.619       0.55      0.634      0.619      0.374\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      14/50      10.6G     0.7724      1.785       1.41      1.141        186        640: 100%|██████████| 1/1 [00:00<00:00,  1.01it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  2.15it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all         15        150      0.853      0.803      0.906      0.703      0.746      0.663      0.756      0.453\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      15/50      10.7G     0.8089      1.606      1.436       1.14        197        640: 100%|██████████| 1/1 [00:00<00:00,  1.00it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  2.06it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all         15        150      0.612      0.794      0.768      0.569      0.548      0.673      0.627      0.387\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      16/50      10.7G      0.741      1.408      1.205      1.042        309        640: 100%|██████████| 1/1 [00:01<00:00,  1.06s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  2.17it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all         15        150      0.546      0.829      0.665      0.428      0.501       0.74      0.536      0.296\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      17/50      10.6G     0.7369      1.296      1.183      1.062        256        640: 100%|██████████| 1/1 [00:01<00:00,  1.00s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  2.18it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all         15        150       0.58       0.81      0.662      0.495       0.56      0.777      0.589      0.317\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      18/50      10.5G     0.8082      1.429      1.114      1.106        220        640: 100%|██████████| 1/1 [00:00<00:00,  1.04it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.92it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all         15        150       0.58       0.81      0.662      0.495       0.56      0.777      0.589      0.317\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      19/50      10.8G     0.7826      1.252      1.124      1.057        241        640: 100%|██████████| 1/1 [00:00<00:00,  1.01it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  2.08it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all         15        150      0.645      0.769      0.733       0.52       0.63      0.744      0.648      0.356\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      20/50      10.7G     0.7525      1.213      1.167       1.06        209        640: 100%|██████████| 1/1 [00:00<00:00,  1.03it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.90it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all         15        150      0.645      0.769      0.733       0.52       0.63      0.744      0.648      0.356\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      21/50      10.8G     0.8324      1.159      1.143      1.119        239        640: 100%|██████████| 1/1 [00:01<00:00,  1.01s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  2.12it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all         15        150      0.707       0.79       0.83      0.643      0.685      0.776      0.791      0.456\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      22/50      10.7G     0.6749      1.326     0.9978      1.033        249        640: 100%|██████████| 1/1 [00:00<00:00,  1.03it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  2.10it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all         15        150      0.707       0.79       0.83      0.643      0.685      0.776      0.791      0.456\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      23/50      10.9G     0.7054      1.035      1.106      1.016        267        640: 100%|██████████| 1/1 [00:01<00:00,  1.03s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  2.08it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all         15        150      0.727      0.799      0.832       0.65      0.708      0.787      0.798      0.483\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      24/50      10.7G        0.7       1.24     0.9336      1.047        240        640: 100%|██████████| 1/1 [00:00<00:00,  1.01it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  2.14it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all         15        150      0.727      0.799      0.832       0.65      0.708      0.787      0.798      0.483\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      25/50        11G     0.7058      1.306     0.9498     0.9953        296        640: 100%|██████████| 1/1 [00:01<00:00,  1.03s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  2.10it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all         15        150      0.604      0.856      0.771       0.61       0.56      0.814      0.711      0.434\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      26/50      10.7G     0.7321      1.212     0.9826      1.041        229        640: 100%|██████████| 1/1 [00:01<00:00,  1.01s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  2.16it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all         15        150      0.604      0.856      0.771       0.61       0.56      0.814      0.711      0.434\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      27/50      10.8G     0.7044      1.143      0.903      1.042        210        640: 100%|██████████| 1/1 [00:01<00:00,  1.04s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  2.06it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all         15        150      0.535      0.736      0.678      0.545      0.507      0.713      0.636      0.405\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      28/50      10.7G     0.6795      1.035     0.8569     0.9865        298        640: 100%|██████████| 1/1 [00:01<00:00,  1.02s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  2.03it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all         15        150      0.535      0.736      0.678      0.545      0.507      0.713      0.636      0.405\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      29/50      10.8G     0.6989      1.075     0.9135      1.065        232        640: 100%|██████████| 1/1 [00:01<00:00,  1.05s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  2.01it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all         15        150      0.614       0.76      0.761      0.608      0.627      0.673      0.721      0.479\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      30/50      10.7G      0.748      1.309     0.9475      1.029        244        640: 100%|██████████| 1/1 [00:00<00:00,  1.01it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  2.16it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all         15        150      0.614       0.76      0.761      0.608      0.627      0.673      0.721      0.479\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      31/50      10.8G     0.6424      1.049     0.8343     0.9722        238        640: 100%|██████████| 1/1 [00:01<00:00,  1.02s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  2.11it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all         15        150      0.704      0.819      0.785      0.629      0.678      0.798      0.751      0.495\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      32/50      10.6G     0.6418      1.165       0.75      1.019        230        640: 100%|██████████| 1/1 [00:00<00:00,  1.01it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.99it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all         15        150      0.704      0.819      0.785      0.629      0.678      0.798      0.751      0.495\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      33/50      10.8G     0.6784     0.9411     0.7967      1.006        227        640: 100%|██████████| 1/1 [00:01<00:00,  1.01s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  2.15it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all         15        150      0.802      0.857      0.862      0.731      0.785      0.846      0.836       0.56\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      34/50      10.6G     0.6125      1.003     0.7553     0.9894        216        640: 100%|██████████| 1/1 [00:00<00:00,  1.03it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  2.22it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all         15        150      0.802      0.857      0.862      0.731      0.785      0.846      0.836       0.56\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      35/50      10.9G     0.6516      1.295     0.7751      1.009        264        640: 100%|██████████| 1/1 [00:01<00:00,  1.03s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  2.19it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all         15        150        0.8      0.867      0.871      0.732       0.78      0.853      0.841      0.581\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      36/50      10.7G     0.6978      1.142     0.7847      1.017        262        640: 100%|██████████| 1/1 [00:00<00:00,  1.04it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  2.11it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all         15        150        0.8      0.867      0.871      0.732       0.78      0.853      0.841      0.581\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      37/50      10.8G      0.675     0.9175     0.7547      1.033        210        640: 100%|██████████| 1/1 [00:00<00:00,  1.00it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  2.17it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all         15        150      0.786      0.895        0.9      0.747      0.766      0.859      0.869      0.592\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      38/50      10.6G     0.6066      1.069     0.7789     0.9857        223        640: 100%|██████████| 1/1 [00:00<00:00,  1.03it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  2.19it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all         15        150      0.786      0.895        0.9      0.747      0.766      0.859      0.869      0.592\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      39/50      10.9G     0.5667      1.234     0.7227     0.9691        234        640: 100%|██████████| 1/1 [00:01<00:00,  1.02s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  2.16it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all         15        150      0.843      0.875      0.902      0.757       0.83      0.834      0.878      0.608\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      40/50      10.7G     0.6034     0.8481     0.6639      0.972        259        640: 100%|██████████| 1/1 [00:01<00:00,  1.01s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.95it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all         15        150      0.843      0.875      0.902      0.757       0.83      0.834      0.878      0.608\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Closing dataloader mosaic\n",
            "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, method='weighted_average', num_output_channels=3), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      41/50      10.7G     0.6043     0.6966     0.6556      1.001        149        640: 100%|██████████| 1/1 [00:01<00:00,  1.47s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.70it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all         15        150       0.71      0.847      0.894      0.774      0.682      0.819      0.865      0.598\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      42/50      10.5G     0.5159     0.6465     0.5853     0.9324        146        640: 100%|██████████| 1/1 [00:00<00:00,  1.02it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.74it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all         15        150       0.71      0.847      0.894      0.774      0.682      0.819      0.865      0.598\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      43/50      10.7G     0.5766     0.7474     0.5944     0.9805        145        640: 100%|██████████| 1/1 [00:00<00:00,  1.00it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.63it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all         15        150      0.854       0.67      0.902      0.788      0.901      0.612      0.881        0.6\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      44/50      10.5G     0.5412     0.7117     0.5806     0.9615        145        640: 100%|██████████| 1/1 [00:00<00:00,  1.02it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  2.13it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all         15        150      0.854       0.67      0.902      0.788      0.901      0.612      0.881        0.6\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      45/50      10.7G     0.5292     0.6387     0.5812      0.902        148        640: 100%|██████████| 1/1 [00:01<00:00,  1.12s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.78it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all         15        150      0.685      0.845      0.921      0.787      0.668      0.828      0.907      0.623\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      46/50      10.5G     0.5356     0.6496     0.5454     0.9224        142        640: 100%|██████████| 1/1 [00:00<00:00,  1.08it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  2.18it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all         15        150      0.685      0.845      0.921      0.787      0.668      0.828      0.907      0.623\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      47/50      10.7G     0.5723     0.7786     0.5765     0.9589        145        640: 100%|██████████| 1/1 [00:00<00:00,  1.02it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  2.12it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all         15        150       0.92      0.854      0.922      0.794      0.905      0.842      0.905      0.632\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      48/50      10.5G     0.4851     0.6372     0.5179     0.9244        146        640: 100%|██████████| 1/1 [00:00<00:00,  1.06it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  2.19it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all         15        150       0.92      0.854      0.922      0.794      0.905      0.842      0.905      0.632\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      49/50      10.7G       0.56       0.68     0.5375      1.012        140        640: 100%|██████████| 1/1 [00:00<00:00,  1.02it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  2.15it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all         15        150      0.941      0.891      0.924       0.81      0.924      0.877      0.903      0.637\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      50/50      10.5G     0.5099     0.6572     0.5247     0.9345        146        640: 100%|██████████| 1/1 [00:00<00:00,  1.02it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.89it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all         15        150      0.941      0.891      0.924       0.81      0.924      0.877      0.903      0.637\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "50 epochs completed in 0.075 hours.\n",
            "Optimizer stripped from /content/runs/train/yolov8_seg_custom3/weights/last.pt, 92.3MB\n",
            "Optimizer stripped from /content/runs/train/yolov8_seg_custom3/weights/best.pt, 92.3MB\n",
            "\n",
            "Validating /content/runs/train/yolov8_seg_custom3/weights/best.pt...\n",
            "Ultralytics 8.3.146 🚀 Python-3.11.12 torch-2.6.0+cu124 CUDA:0 (Tesla T4, 15095MiB)\n",
            "YOLOv8l-seg summary (fused): 125 layers, 45,915,743 parameters, 0 gradients, 220.1 GFLOPs\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95):   0%|          | 0/1 [00:00<?, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING ⚠️ Limiting validation plots to first 50 items per image for speed...\n",
            "WARNING ⚠️ Limiting validation plots to first 50 items per image for speed...\n",
            "WARNING ⚠️ Limiting validation plots to first 50 items per image for speed...\n",
            "WARNING ⚠️ Limiting validation plots to first 50 items per image for speed...\n",
            "WARNING ⚠️ Limiting validation plots to first 50 items per image for speed...\n",
            "WARNING ⚠️ Limiting validation plots to first 50 items per image for speed...\n",
            "WARNING ⚠️ Limiting validation plots to first 50 items per image for speed...\n",
            "WARNING ⚠️ Limiting validation plots to first 50 items per image for speed...\n",
            "WARNING ⚠️ Limiting validation plots to first 50 items per image for speed...\n",
            "WARNING ⚠️ Limiting validation plots to first 50 items per image for speed...\n",
            "WARNING ⚠️ Limiting validation plots to first 50 items per image for speed...\n",
            "WARNING ⚠️ Limiting validation plots to first 50 items per image for speed...\n",
            "WARNING ⚠️ Limiting validation plots to first 50 items per image for speed...\n",
            "WARNING ⚠️ Limiting validation plots to first 50 items per image for speed...\n",
            "WARNING ⚠️ Limiting validation plots to first 50 items per image for speed...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  2.01it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all         15        150      0.941      0.891      0.924       0.81      0.924      0.877      0.904      0.637\n",
            "           dotted-line         15         87      0.985      0.755      0.888       0.67      0.895      0.685       0.78      0.443\n",
            "             left-lane         15         15      0.994          1      0.995      0.931      0.995          1      0.995      0.757\n",
            "             left-line         15         15      0.974          1      0.995      0.863      0.974          1      0.995      0.694\n",
            "            right-iine         14         17      0.854      0.765      0.775      0.734      0.856      0.765      0.778      0.599\n",
            "            right-lane         15         16        0.9      0.938      0.969      0.854      0.901      0.938      0.969      0.696\n",
            "Speed: 0.2ms preprocess, 20.9ms inference, 0.0ms loss, 1.5ms postprocess per image\n",
            "Results saved to \u001b[1m/content/runs/train/yolov8_seg_custom3\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 학습된 모델 로드(폴더에 맞도록)\n",
        "model = YOLO('/content/runs/train/yolov8_seg_custom3/weights/best.pt')\n",
        "\n",
        "# 테스트 실행\n",
        "results = model.predict(\n",
        "    source='/content/dataset/train/images',  # 테스트 이미지 경로\n",
        "    save=True,                              # 결과 저장\n",
        "    save_txt=True,                          # 텍스트 결과도 저장\n",
        "    conf=0.5,                               # 신뢰도 임계값\n",
        "    project='/content/runs/detect',         # 저장 프로젝트 경로\n",
        "    name='test_results'                     # 폴더 이름 지정\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b1PG5-YbJjSs",
        "outputId": "5a081c68-e1fd-4a5f-e7ac-ab1bfc1ecace"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/15 /content/dataset/train/images/121-_jpg.rf.d36e70fd2de33b8b6cc77160a7088b6f.jpg: 640x640 4 dotted-lines, 1 left-lane, 1 left-line, 1 right-iine, 1 right-lane, 76.0ms\n",
            "image 2/15 /content/dataset/train/images/122-_jpg.rf.9c46815cf488d2659f9a7258abf27029.jpg: 640x640 5 dotted-lines, 1 left-lane, 1 left-line, 1 right-iine, 2 right-lanes, 56.2ms\n",
            "image 3/15 /content/dataset/train/images/123-_jpg.rf.a228c18f448d90fe3ef627dd4b92b7ed.jpg: 640x640 4 dotted-lines, 1 left-lane, 1 left-line, 1 right-iine, 1 right-lane, 56.2ms\n",
            "image 4/15 /content/dataset/train/images/124-_jpg.rf.9ab2f9ebb0279f89ce2b5dacb8b1083f.jpg: 640x640 5 dotted-lines, 1 left-lane, 1 left-line, 1 right-iine, 2 right-lanes, 56.2ms\n",
            "image 5/15 /content/dataset/train/images/125-_jpg.rf.e4a04a05e6a6374afe927c8ff9045546.jpg: 640x640 4 dotted-lines, 1 left-lane, 1 left-line, 1 right-iine, 1 right-lane, 49.3ms\n",
            "image 6/15 /content/dataset/train/images/126-_jpg.rf.52a46fd704e8f5eee804bc7d95104d8e.jpg: 640x640 5 dotted-lines, 1 left-lane, 1 left-line, 1 right-iine, 1 right-lane, 40.8ms\n",
            "image 7/15 /content/dataset/train/images/127-_jpg.rf.46c2cbd52bea81fb4bffd502d92cbb04.jpg: 640x640 5 dotted-lines, 1 left-lane, 1 left-line, 1 right-iine, 1 right-lane, 40.8ms\n",
            "image 8/15 /content/dataset/train/images/128-_jpg.rf.026b7a4bce903ffb6b692fe4265b9393.jpg: 640x640 4 dotted-lines, 1 left-lane, 1 left-line, 1 right-iine, 1 right-lane, 42.1ms\n",
            "image 9/15 /content/dataset/train/images/129-_jpg.rf.da642d39016bb4ea3453e6126a3ba956.jpg: 640x640 5 dotted-lines, 1 left-lane, 1 left-line, 1 right-iine, 1 right-lane, 42.3ms\n",
            "image 10/15 /content/dataset/train/images/130-_jpg.rf.0075a5215851d7d1218b78d4c9169c81.jpg: 640x640 5 dotted-lines, 1 left-lane, 1 left-line, 1 right-iine, 1 right-lane, 38.7ms\n",
            "image 11/15 /content/dataset/train/images/131-_jpg.rf.155c503822acb1429a74645b2dd31584.jpg: 640x640 4 dotted-lines, 1 left-lane, 1 left-line, 1 right-iine, 1 right-lane, 41.0ms\n",
            "image 12/15 /content/dataset/train/images/132-_jpg.rf.e122b352a1f34bee5bccf7f999136c24.jpg: 640x640 4 dotted-lines, 1 left-lane, 1 left-line, 1 right-iine, 1 right-lane, 42.8ms\n",
            "image 13/15 /content/dataset/train/images/133-_jpg.rf.a8edc577127d808151a5509733a01a3b.jpg: 640x640 5 dotted-lines, 1 left-lane, 1 left-line, 1 right-iine, 1 right-lane, 41.0ms\n",
            "image 14/15 /content/dataset/train/images/134-_jpg.rf.538c2b19ef92599439257bf73c2a4343.jpg: 640x640 5 dotted-lines, 1 left-lane, 1 left-line, 1 right-iine, 1 right-lane, 40.9ms\n",
            "image 15/15 /content/dataset/train/images/135-_jpg.rf.895917461ff3b64960b12caa4a11cdd7.jpg: 640x640 4 dotted-lines, 1 left-lane, 1 left-line, 1 right-iine, 1 right-lane, 42.7ms\n",
            "Speed: 2.0ms preprocess, 47.1ms inference, 4.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "Results saved to \u001b[1m/content/runs/detect/test_results\u001b[0m\n",
            "15 labels saved to /content/runs/detect/test_results/labels\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "\n",
        "def draw_enhanced_results(image_path, results):\n",
        "    \"\"\"세그멘테이션 마스크를 이미지 위에 시각화\"\"\"\n",
        "    # 이미지 로드\n",
        "    img = cv2.imread(image_path)\n",
        "    img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "    # 클래스 색상 정의\n",
        "    class_names = ['dotted-line', 'left_lane', 'left_line', 'right_lane', 'right_line']\n",
        "    colors = [(255, 0, 0), (0, 255, 0), (0, 0, 255), (255, 255, 0), (255, 0, 255)]\n",
        "\n",
        "    for result in results:\n",
        "        masks = result.masks  # 마스크 객체\n",
        "\n",
        "        if masks is not None and masks.data is not None:\n",
        "            mask_data = masks.data.cpu().numpy()  # (N, H, W)\n",
        "            cls_list = result.boxes.cls.cpu().numpy().astype(int)  # 클래스 인덱스 리스트\n",
        "            conf_list = result.boxes.conf.cpu().numpy()  # 신뢰도\n",
        "\n",
        "            for i in range(len(mask_data)):\n",
        "                mask = mask_data[i]\n",
        "                cls_id = cls_list[i]\n",
        "                conf = conf_list[i]\n",
        "\n",
        "                # 마스크 색상 및 클래스 이름\n",
        "                color = colors[cls_id % len(colors)]\n",
        "                class_name = class_names[cls_id] if cls_id < len(class_names) else f'class_{cls_id}'\n",
        "                label = f'{class_name}: {conf:.2f}'\n",
        "\n",
        "                # 마스크를 컬러로 적용\n",
        "                colored_mask = np.zeros_like(img_rgb, dtype=np.uint8)\n",
        "                for c in range(3):\n",
        "                    colored_mask[:, :, c] = mask * color[c]\n",
        "\n",
        "                # 반투명하게 overlay\n",
        "                img_rgb = cv2.addWeighted(img_rgb, 1.0, colored_mask, 0.4, 0)\n",
        "\n",
        "                # 마스크 경계 추출하여 텍스트 위치 추정\n",
        "                contours, _ = cv2.findContours((mask * 255).astype(np.uint8), cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
        "                if contours:\n",
        "                    x, y, w, h = cv2.boundingRect(contours[0])\n",
        "                    # 라벨 텍스트\n",
        "                    (text_width, text_height), _ = cv2.getTextSize(label, cv2.FONT_HERSHEY_SIMPLEX, 0.7, 2)\n",
        "                    cv2.rectangle(img_rgb, (x, y - text_height - 10), (x + text_width, y), color, -1)\n",
        "                    cv2.putText(img_rgb, label, (x, y - 5), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 255, 255), 2)\n",
        "\n",
        "    return img_rgb\n"
      ],
      "metadata": {
        "id": "IpTy8s9PSDIZ"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "image_dir = '/content/dataset/test/images/'\n",
        "test_images = sorted([img for img in os.listdir(image_dir) if img.lower().endswith(('.png', '.jpg', '.jpeg'))])\n",
        "\n",
        "\n",
        "for i, img_name in enumerate(test_images[:5]):  # 처음 5개만\n",
        "    img_path = f'/content/dataset/test/images/{img_name}'\n",
        "\n",
        "    # 예측 실행\n",
        "    result = model.predict(img_path, conf=0.5, verbose=False)\n",
        "\n",
        "    # 향상된 시각화\n",
        "    enhanced_img = draw_enhanced_results(img_path, result)\n",
        "\n",
        "    # 결과 표시\n",
        "    plt.figure(figsize=(12, 8))\n",
        "    plt.imshow(enhanced_img)\n",
        "    plt.title(f'Detection Result: {img_name}')\n",
        "    plt.axis('off')\n",
        "    plt.show()\n"
      ],
      "metadata": {
        "id": "KZI6ZP0LbDMZ"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import shutil\n",
        "from google.colab import files\n",
        "\n",
        "# 1. zip 파일로 압축 (기존 zip 파일이 있다면 덮어씌움)\n",
        "shutil.make_archive('/content/runs_backup', 'zip', '/content/runs')\n",
        "\n",
        "# 2. 다운로드 링크 제공\n",
        "files.download('/content/runs_backup.zip')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "8-OsCHrZ7BFI",
        "outputId": "f27c46d1-1c7d-44bf-9a86-4d1a8cd0a401"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_dfe2a257-7703-4571-a5a0-48f31af53294\", \"runs_backup.zip\", 176760703)"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "source": [
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# YOLO 예측 + 시각화 함수 (콜라보용)\n",
        "image_dir = '/content/dataset/train/images'\n",
        "test_images = sorted([img for img in os.listdir(image_dir) if img.lower().endswith(('.png', '.jpg', '.jpeg'))])\n",
        "\n",
        "# Check if test_images is empty before proceeding\n",
        "if not test_images:\n",
        "    print(f\"Warning: No image files found in {image_dir}. Cannot create video.\")\n",
        "else:\n",
        "    frames = []\n",
        "    target_duration = 15  # 목표 동영상 길이 (초)\n",
        "\n",
        "    # 처음 5개만 사용하되, test_images에 이미지가 5개 미만일 경우 전체 사용\n",
        "    images_to_process = test_images[:5] if len(test_images) >= 5 else test_images\n",
        "\n",
        "    for i, img_name in enumerate(images_to_process):\n",
        "        img_path = os.path.join(image_dir, img_name)\n",
        "\n",
        "        # 예측 실행\n",
        "        # Wrap the prediction call in a try-except block to catch potential issues with individual images\n",
        "        try:\n",
        "            result = model.predict(img_path, conf=0.5, verbose=False)\n",
        "\n",
        "            # 향상된 시각화\n",
        "            enhanced_img = draw_enhanced_results(img_path, result)\n",
        "\n",
        "            # RGB -> BGR (OpenCV용)\n",
        "            bgr_img = cv2.cvtColor(np.array(enhanced_img), cv2.COLOR_RGB2BGR)\n",
        "\n",
        "            # 모든 프레임 사이즈를 동일하게 유지\n",
        "            # Use the shape of the first successful frame as the target size\n",
        "            if not frames:  # If this is the first frame\n",
        "                target_height, target_width, _ = bgr_img.shape\n",
        "            bgr_img = cv2.resize(bgr_img, (target_width, target_height))\n",
        "\n",
        "            frames.append(bgr_img)\n",
        "        except Exception as e:\n",
        "            print(f\"Error processing image {img_name}: {e}\")\n",
        "            continue  # Skip this image and continue with the next\n",
        "\n",
        "    # 🔄 동영상 생성 (15초 길이, 높은 FPS)\n",
        "    if frames:  # Only attempt to create video if frames were added\n",
        "        video_path = \"/content/detection_results_15sec.mp4\"\n",
        "\n",
        "        # 목표 설정\n",
        "        target_fps = 24  # 부드러운 재생을 위한 목표 FPS\n",
        "        target_total_frames = target_duration * target_fps  # 15초 * 24fps = 360프레임\n",
        "\n",
        "        original_frame_count = len(frames)\n",
        "        print(f\"📊 원본 프레임 수: {original_frame_count}개\")\n",
        "\n",
        "        # 프레임이 부족하면 반복하여 목표 프레임 수 맞추기\n",
        "        extended_frames = []\n",
        "        frames_per_original = max(1, target_total_frames // original_frame_count)  # 각 프레임 반복 횟수\n",
        "\n",
        "        for i in range(target_total_frames):\n",
        "            frame_index = i % original_frame_count  # 순환 반복\n",
        "            extended_frames.append(frames[frame_index])\n",
        "\n",
        "        print(f\"✅ 15초 동영상 생성\")\n",
        "        print(f\"   - 목표 FPS: {target_fps}\")\n",
        "        print(f\"   - 총 프레임: {len(extended_frames)}개\")\n",
        "        print(f\"   - 각 이미지당 약 {target_total_frames // original_frame_count}프레임 반복\")\n",
        "\n",
        "        height, width, _ = frames[0].shape\n",
        "        fourcc = cv2.VideoWriter_fourcc(*'mp4v')  # 코덱 설정\n",
        "\n",
        "        out = cv2.VideoWriter(video_path, fourcc, target_fps, (width, height))\n",
        "\n",
        "        for frame in extended_frames:\n",
        "            out.write(frame)\n",
        "\n",
        "        out.release()\n",
        "        print(f\"✅ 15초 고품질 영상 저장 완료: {video_path}\")\n",
        "\n",
        "        # Colab에서 다운로드 링크 제공\n",
        "        from google.colab import files\n",
        "        files.download(video_path)\n",
        "    else:\n",
        "        print(\"No frames were successfully processed to create a video.\")\n",
        "\n",
        "# 🎯 추가 옵션: 프레임 반복으로 정확히 15초 만들기\n",
        "def create_exact_15sec_video(frames, output_path=\"/content/detection_exact_15sec.mp4\"):\n",
        "    \"\"\"프레임을 반복하여 정확히 15초 동영상 생성\"\"\"\n",
        "    if not frames:\n",
        "        print(\"프레임이 없습니다.\")\n",
        "        return\n",
        "\n",
        "    target_duration = 15  # 목표 시간 (초)\n",
        "    target_fps = 30       # 목표 FPS\n",
        "    target_total_frames = target_duration * target_fps  # 15초 * 30fps = 450프레임\n",
        "\n",
        "    original_frame_count = len(frames)\n",
        "\n",
        "    # 프레임 반복하여 목표 프레임 수 맞추기\n",
        "    extended_frames = []\n",
        "    for i in range(target_total_frames):\n",
        "        frame_index = i % original_frame_count  # 순환 반복\n",
        "        extended_frames.append(frames[frame_index])\n",
        "\n",
        "    # 동영상 생성\n",
        "    height, width, _ = frames[0].shape\n",
        "    fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
        "\n",
        "    out = cv2.VideoWriter(output_path, fourcc, target_fps, (width, height))\n",
        "\n",
        "    for frame in extended_frames:\n",
        "        out.write(frame)\n",
        "\n",
        "    out.release()\n",
        "\n",
        "    print(f\"✅ 정확히 15초 동영상 생성 완료!\")\n",
        "    print(f\"   - 파일: {output_path}\")\n",
        "    print(f\"   - 원본 프레임: {original_frame_count}개\")\n",
        "    print(f\"   - 최종 프레임: {target_total_frames}개\")\n",
        "    print(f\"   - FPS: {target_fps}\")\n",
        "    print(f\"   - 길이: {target_duration}초\")\n",
        "\n",
        "    # Colab에서 다운로드\n",
        "    from google.colab import files\n",
        "    files.download(output_path)\n",
        "\n",
        "# 정확히 15초 동영상도 생성하고 싶다면 아래 줄의 주석을 해제하세요\n",
        "# if frames:\n",
        "#     create_exact_15sec_video(frames)"
      ],
      "cell_type": "code",
      "metadata": {
        "id": "doeUpNmQwunJ",
        "outputId": "944dd4f0-5b3b-478f-c854-a4436b8dc470",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 313
        }
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Results saved to \u001b[1m/content/runs/detect/test_results\u001b[0m\n",
            "15 labels saved to /content/runs/detect/test_results/labels\n",
            "Results saved to \u001b[1m/content/runs/detect/test_results\u001b[0m\n",
            "15 labels saved to /content/runs/detect/test_results/labels\n",
            "Results saved to \u001b[1m/content/runs/detect/test_results\u001b[0m\n",
            "15 labels saved to /content/runs/detect/test_results/labels\n",
            "Results saved to \u001b[1m/content/runs/detect/test_results\u001b[0m\n",
            "15 labels saved to /content/runs/detect/test_results/labels\n",
            "Results saved to \u001b[1m/content/runs/detect/test_results\u001b[0m\n",
            "15 labels saved to /content/runs/detect/test_results/labels\n",
            "📊 원본 프레임 수: 5개\n",
            "✅ 15초 동영상 생성\n",
            "   - 목표 FPS: 24\n",
            "   - 총 프레임: 360개\n",
            "   - 각 이미지당 약 72프레임 반복\n",
            "✅ 15초 고품질 영상 저장 완료: /content/detection_results_15sec.mp4\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_a0af2b8a-2d0f-4846-bd19-46334fa303d2\", \"detection_results_15sec.mp4\", 17502899)"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "tFnYS8pP75VW"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}